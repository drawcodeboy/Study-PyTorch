{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01581dbe",
   "metadata": {},
   "source": [
    "# 모델 매개변수 최적화하기\n",
    "* 데이터에 대해 매개변수를 최적화하여 모델을 학습하고, 검증하고, 테스트 할 차례\n",
    "* 각 반복 단계에서 모델은 출력을 추측하고, 추측과 정답 사이의 오류(손실)를 계산하고,\n",
    "* 매개변수에 대한 오류의 도함수를 수집한 뒤, 경사하강법을 사용하여 이 파라미터들을 optimize한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02fb28d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72916670",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(28*28, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "        \n",
    "model = myNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edd8f25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 512]         401,920\n",
      "              ReLU-3                  [-1, 512]               0\n",
      "            Linear-4                   [-1, 10]           5,130\n",
      "              ReLU-5                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 1.55\n",
      "Estimated Total Size (MB): 1.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b9dd7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "size = len(train_dataloader.dataset)\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "843af0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2b2a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature, label = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a702ce50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb0563",
   "metadata": {},
   "source": [
    "# Hyperparameter\n",
    "* learning rate\n",
    "* epoch\n",
    "* batch_size\n",
    "* loss function\n",
    "* optimizer\n",
    "* 위 4가지 개념에 대한 설명은 생략\n",
    "* optimizer는 코드가 좀 중요해 보여서 적어두겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bcf833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "epochs = 5\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90f1d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2723ecb3",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "* 최적화는 각 학습 단계에서 모델의 오류를 줄이기 위해 모델 매개변수를 조정하는 과정이다.\n",
    "* 최적화 알고리즘은 이 과정이 수행되는 방식(여기에서는 SGD)를 정의 한다.\n",
    "* <b>모든 최적화 절차는 optimizer 객체에 캡슐화된다.</b>\n",
    "* 여기서는 SGD 옵티마이저를 사용하고 있으며, PyTorch에는 ADAM이나 RMSProp과 같은 다른 종류의 모델과 데이터에서 더 잘 동작하는 다양한 옵티마이저가 있다.\n",
    "\n",
    "* 학습하려는 모델의 매개변수와 learning rate 하이퍼 파라미터를 등록하여 옵티마이저를 초기화 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76e888ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8c157",
   "metadata": {},
   "source": [
    "* 학습 단계(loop)에서 최적화는 세단계로 이뤄집니다.\n",
    "    * <code>optimizer.zero_grad()</code>를 호출하여 모델 매개변수의 변화도를 재설정한다. 기본적으로 변화도는 더해지기 때문에 중복 계산을 막기 위해 반복할 때마다 명시적으로 0으로 설정한다.\n",
    "        * 각 Tensor에 대해 이미 .grad라는 속성에 대해서 optimizer가 연산을 하는 것인가?\n",
    "    * <code>loss.backward()</code>를 호출하여 prediction loss를 역전파한다.\n",
    "    * 변화도를 계산한 뒤에는 <code>optimzer.step()</code>을 호출하여 역전파 단계에서 수집된 변화도로 매개변수를 조정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7822c5b",
   "metadata": {},
   "source": [
    "### 번외) dataLoader에서 data 뽑아내는 법\n",
    "* <code>iter(), next()</code>를 통해서 뽑아낸다.\n",
    "* 이는 iterable한 object에 대해서 <code>object.\\_\\_iter\\_\\_()</code>과 <code>object.\\_\\_next\\_\\_()</code>를 호출하는 것과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0aca631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9, 1, 0, 6, 4, 3, 1, 4, 8,\n",
      "        4, 3, 0, 2, 4, 4, 5, 3, 6, 6, 0, 8, 5, 2, 1, 6, 6, 7, 9, 5, 9, 2, 7, 3,\n",
      "        0, 3, 3, 3, 7, 2, 2, 6, 6, 8, 3, 3, 5, 0, 5, 5])]\n"
     ]
    }
   ],
   "source": [
    "data = train_dataloader.__iter__()\n",
    "# == data = iter(train_dataloader)\n",
    "print(data.__next__())\n",
    "# == print(next(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5095527d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(train_dataloader.dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c431ddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "li = np.array([3, 5, 6, 8])\n",
    "print(type(li.argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80ff3a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # 1 Epoch\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Forward Propagtion\n",
    "        # 예측(Prediction)과 loss 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Back Propagation\n",
    "        optimizer.zero_grad() # 변화 값 초기화\n",
    "        loss.backward() # loss에서 back propagation\n",
    "        optimizer.step() # gradient에 대한 optimzer의 계산\n",
    "        \n",
    "        if(batch % 100 == 0):\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset) # 데이터셋 크기\n",
    "    num_batches = len(dataloader) # Batch Size\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item() # 여기 문법이 어떻게 이렇게 되지\n",
    "            # print((pred.argmax(1) == y))\n",
    "            # print((pred.argmax(1) == y).type(torch.float))\n",
    "            # print((pred.argmax(1) == y).type(torch.float).sum()) # Batch라서 Sum이 필요했음\n",
    "            # print((pred.argmax(1) == y).type(torch.float).sum().item()) # Sum(Aggregate)를 했으니 원소 값을 가져오는 item() 쓴 거\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test Error: \\n Accuracy: {100*correct:>0.1f}%, Avg loss: {test_loss:>8f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91d1d776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "---------------------------\n",
      "loss: 1.554697 [   64/60000]\n",
      "loss: 1.447941 [ 6464/60000]\n",
      "loss: 1.420570 [12864/60000]\n",
      "loss: 1.601423 [19264/60000]\n",
      "loss: 1.384752 [25664/60000]\n",
      "loss: 1.480931 [32064/60000]\n",
      "loss: 1.538543 [38464/60000]\n",
      "loss: 1.556124 [44864/60000]\n",
      "loss: 1.491038 [51264/60000]\n",
      "loss: 1.415847 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.450528 \n",
      "\n",
      "Epoch 2\n",
      "---------------------------\n",
      "loss: 1.433963 [   64/60000]\n",
      "loss: 1.333974 [ 6464/60000]\n",
      "loss: 1.302448 [12864/60000]\n",
      "loss: 1.511111 [19264/60000]\n",
      "loss: 1.281652 [25664/60000]\n",
      "loss: 1.396314 [32064/60000]\n",
      "loss: 1.458098 [38464/60000]\n",
      "loss: 1.489570 [44864/60000]\n",
      "loss: 1.408708 [51264/60000]\n",
      "loss: 1.348030 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.372590 \n",
      "\n",
      "Epoch 3\n",
      "---------------------------\n",
      "loss: 1.348174 [   64/60000]\n",
      "loss: 1.255614 [ 6464/60000]\n",
      "loss: 1.218817 [12864/60000]\n",
      "loss: 1.447169 [19264/60000]\n",
      "loss: 1.210530 [25664/60000]\n",
      "loss: 1.336095 [32064/60000]\n",
      "loss: 1.402094 [38464/60000]\n",
      "loss: 1.441121 [44864/60000]\n",
      "loss: 1.348071 [51264/60000]\n",
      "loss: 1.301492 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 1.315378 \n",
      "\n",
      "Epoch 4\n",
      "---------------------------\n",
      "loss: 1.283275 [   64/60000]\n",
      "loss: 1.198150 [ 6464/60000]\n",
      "loss: 1.156023 [12864/60000]\n",
      "loss: 1.399534 [19264/60000]\n",
      "loss: 1.159368 [25664/60000]\n",
      "loss: 1.289668 [32064/60000]\n",
      "loss: 1.359532 [38464/60000]\n",
      "loss: 1.403835 [44864/60000]\n",
      "loss: 1.299831 [51264/60000]\n",
      "loss: 1.266629 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 1.270507 \n",
      "\n",
      "Epoch 5\n",
      "---------------------------\n",
      "loss: 1.230217 [   64/60000]\n",
      "loss: 1.153307 [ 6464/60000]\n",
      "loss: 1.106037 [12864/60000]\n",
      "loss: 1.361858 [19264/60000]\n",
      "loss: 1.119911 [25664/60000]\n",
      "loss: 1.252384 [32064/60000]\n",
      "loss: 1.325204 [38464/60000]\n",
      "loss: 1.374004 [44864/60000]\n",
      "loss: 1.260304 [51264/60000]\n",
      "loss: 1.238163 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1.233601 \n",
      "\n",
      "Epoch 6\n",
      "---------------------------\n",
      "loss: 1.185067 [   64/60000]\n",
      "loss: 1.116473 [ 6464/60000]\n",
      "loss: 1.064677 [12864/60000]\n",
      "loss: 1.330948 [19264/60000]\n",
      "loss: 1.088766 [25664/60000]\n",
      "loss: 1.221235 [32064/60000]\n",
      "loss: 1.296404 [38464/60000]\n",
      "loss: 1.349796 [44864/60000]\n",
      "loss: 1.226971 [51264/60000]\n",
      "loss: 1.214055 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 1.202336 \n",
      "\n",
      "Epoch 7\n",
      "---------------------------\n",
      "loss: 1.146009 [   64/60000]\n",
      "loss: 1.084604 [ 6464/60000]\n",
      "loss: 1.029358 [12864/60000]\n",
      "loss: 1.304978 [19264/60000]\n",
      "loss: 1.063055 [25664/60000]\n",
      "loss: 1.195449 [32064/60000]\n",
      "loss: 1.271377 [38464/60000]\n",
      "loss: 1.329748 [44864/60000]\n",
      "loss: 1.198129 [51264/60000]\n",
      "loss: 1.193133 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 1.175577 \n",
      "\n",
      "Epoch 8\n",
      "---------------------------\n",
      "loss: 1.111605 [   64/60000]\n",
      "loss: 1.056896 [ 6464/60000]\n",
      "loss: 0.998715 [12864/60000]\n",
      "loss: 1.282769 [19264/60000]\n",
      "loss: 1.041896 [25664/60000]\n",
      "loss: 1.174010 [32064/60000]\n",
      "loss: 1.249580 [38464/60000]\n",
      "loss: 1.313220 [44864/60000]\n",
      "loss: 1.173398 [51264/60000]\n",
      "loss: 1.174495 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 1.152429 \n",
      "\n",
      "Epoch 9\n",
      "---------------------------\n",
      "loss: 1.080915 [   64/60000]\n",
      "loss: 1.032260 [ 6464/60000]\n",
      "loss: 0.971966 [12864/60000]\n",
      "loss: 1.263591 [19264/60000]\n",
      "loss: 1.023638 [25664/60000]\n",
      "loss: 1.155779 [32064/60000]\n",
      "loss: 1.230188 [38464/60000]\n",
      "loss: 1.299526 [44864/60000]\n",
      "loss: 1.152338 [51264/60000]\n",
      "loss: 1.157521 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 1.132096 \n",
      "\n",
      "Epoch 10\n",
      "---------------------------\n",
      "loss: 1.053850 [   64/60000]\n",
      "loss: 1.010363 [ 6464/60000]\n",
      "loss: 0.948372 [12864/60000]\n",
      "loss: 1.246839 [19264/60000]\n",
      "loss: 1.007942 [25664/60000]\n",
      "loss: 1.140188 [32064/60000]\n",
      "loss: 1.212592 [38464/60000]\n",
      "loss: 1.288051 [44864/60000]\n",
      "loss: 1.134059 [51264/60000]\n",
      "loss: 1.141903 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.114041 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optmizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t + 1}\\n---------------------------')\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
